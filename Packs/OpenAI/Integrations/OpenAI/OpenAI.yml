commonfields:
  id: OpenAI
  version: -1
name: OpenAI
display: OpenAI
category: Messaging and Conferencing
description: This integration leverages the OpenAI and Azure OpenAI REST APIs to generate human-like responses to text prompts. The APIs provide access to OpenAI's powerful language models including the GPT-3.5 model series. These models can be easily adapted to your specific task including but not limited to content generation, summarization, semantic search, and natural language to code translation.
configuration:
- display: 'Server URL: (e.g. https://api.openai.com/)'
  name: url
  defaultvalue: https://api.openai.com/
  type: 0
  required: true
  section: Connect
- display: API Key
  name: apikey
  type: 4
  required: true
  additionalinfo: OpenAI API key
- display: Use Azure OpenAI?
  name: is_azure
  type: 8
  required: false
  additionalinfo: Whether to use Azure OpenAI (https://your-resource-name.openai.azure.com) instead of standard OpenAI (https://api.openai.com). Default value is False.
  defaultvalue: "false"
- display: Trust any certificate (not secure)
  name: insecure
  type: 8
  required: false
- display: Use system proxy settings
  name: proxy
  required: false
  type: 8
- additionalinfo: Used for Azure OpenAI only. Default value is "2023-09-01-preview".
  defaultvalue: 2023-09-01-preview
  display: API Version
  name: version
  required: false
  type: 0
- additionalinfo: Model to use for the integration Test if different from the OpenAI API default Chat model
  display: Model to Use for Test
  name: test_model
  required: false
  type: 0
script:
  script: ''
  type: python
  commands:
  - name: openai-chatgpt
    arguments:
    - name: prompt
      required: true
      description: Add your question or text.
    - name: model
      auto: PREDEFINED
      predefined:
      - gpt-4
      - gpt-3.5-turbo
      description: Name of model to use. For Azure OpenAI, this should be the name of the DEPLOYMENT, not the generic model name.
      defaultValue: gpt-3.5-turbo
    outputs:
    - contextPath: OpenAI.ChatGPTResponse.ChatGPTResponse
      description: ChatGPT response.
    - contextPath: OpenAI.ChatGPTResponse.CreatedTime
      description: Response created time as Unix timestamp.
    - contextPath: OpenAI.ChatGPTResponse.Model
      description: Model that generated the response.
    - contextPath: OpenAI.ChatGPTResponse.NumberOfCompletionTokens
      description: Number of tokens in the completion (response).
    - contextPath: OpenAI.ChatGPTResponse.NumberOfPromptTokens
      description: Number of tokens in the prompt (input).
    - contextPath: OpenAI.ChatGPTResponse.NumberOfTotalTokens
      description: Total number of tokens in the completion and prompt.
    - contextPath: OpenAI.ChatGPTResponse.id
      description: ChatGPT response ID.
    description: Send prompt to OpenAI ChatGPT.
  - arguments:
    - description: Instruction.
      name: prompt
      required: true
    - auto: PREDEFINED
      defaultValue: gpt-3.5-turbo-instruct
      description: The model which will generate the completion. Some models are suitable for natural language tasks, others specialize in code. For Azure OpenAI, this should be the name of the DEPLOYMENT, not the generic model name.
      name: model
      predefined:
      - gpt-3.5-turbo-instruct
      - text-davinci-003
      - text-curie-001
      - text-babbage-001
      - text-ada-001
      - code-davinci-002
      - code-cushman-001
    - defaultValue: "0.7"
      description: 'Controls randomness: Lowering results in less random completions.'
      name: temperature
    - defaultValue: "256"
      description: The maximum number of tokens to generate.
      name: max_tokens
    - defaultValue: "1"
      description: 'Controls Diversity via nucleus sampling: 0.5 means half of all likihood-weighted options are considered.'
      name: top_p
    - defaultValue: "0"
      description: How much to penalize new tokens based on their existing frequency in the text so far. Decreases the model's likelihood to repeat the same line verbatim.
      name: frequency_penalty
    - defaultValue: "0"
      description: How much to penalize new tokens based on whether they appear in the text so far. Increases the model's likelihood to talk about new topics.
      name: presence_penalty
    - defaultValue: "1"
      description: Generates best_of completions server-side and returns the "best" (the one with the lowest log probability per token). Results can't be streamed. When used with n, best_of controls the number of candidate completions and n specifies how many to return â€“ best_of must be greater than n. Note- Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop. This parameter cannot be used with gpt-35-turbo.
      name: best_of
    - description: Up to four sequences where the API will stop generating further tokens. The returned text won't contain the stop sequence.
      name: stop
    description: Enter an instruction and watch the API respond with a completion that attempts to match the context or pattern you provided.
    name: openai-completions
    outputs:
    - contextPath: OpenAI.Completions.id
      description: Id of the returned completion.
      type: string
    - contextPath: OpenAI.Completions.model
      description: The model which will generate the completion.
      type: string
    - contextPath: OpenAI.Completions.text
      description: Completed text generated by OpenAI?
      type: string
  dockerimage: demisto/python3:3.10.13.83255
  runonce: false
  subtype: python3
fromversion: 6.5.0
tests:
- No tests (auto formatted)
