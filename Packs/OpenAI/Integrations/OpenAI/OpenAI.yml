category: Messaging and Conferencing
commonfields:
  id: OpenAI
  version: -1
configuration:
- defaultvalue: https://api.openai.com/
  display: 'Server URL: (e.g. https://api.openai.com/)'
  name: url
  required: true
  section: Connect
  type: 0
- additionalinfo: OpenAI API key
  display: API Key
  name: apikey
  required: false
  type: 4
- additionalinfo: Whether to use Azure OpenAI (https://your-resource-name.openai.azure.com) instead of standard OpenAI (https://api.openai.com)
  defaultvalue: "false"
  display: Use Azure OpenAI?
  name: is_azure
  required: false
  type: 8
- display: Trust any certificate (not secure)
  name: insecure
  required: false
  type: 8
- display: Use system proxy settings
  name: proxy
  required: false
  type: 8
- additionalinfo: Used for Azure OpenAI only. Default value is "2023-03-15-preview".
  defaultvalue: 2023-03-15-preview
  display: API Version
  name: version
  required: false
  type: 0
- additionalinfo: Model to use for the integration Test if different from the default model, "text-davinci-003"
  display: Model to Use for Test
  name: test_model
  required: false
  type: 0
description: This integration leverages the OpenAI and Azure OpenAI REST APIs to generate human-like responses to text prompts. The APIs provide access to OpenAI's powerful language models including the GPT-3.5 model series. These models can be easily adapted to your specific task including but not limited to content generation, summarization, semantic search, and natural language to code translation.
display: OpenAI
name: OpenAI
script:
  commands:
  - arguments:
    - description: Add your question or text
      name: prompt
      required: true
    - auto: PREDEFINED
      defaultValue: gpt-3.5-turbo
      description: Name of model to use. For Azure OpenAI, this should be the name of the DEPLOYMENT, not the generic model name.
      name: model
      predefined:
      - gpt-3.5-turbo
    description: Send prompt to OpenAI ChatGPT
    name: openai-chatgpt
    outputs:
    - contextPath: OpenAI.ChatGPTResponse.ChatGPT Response
      description: ChatGPT response
    - contextPath: OpenAI.ChatGPTResponse.Created Time
      description: Response created time as Unix timestamp
    - contextPath: OpenAI.ChatGPTResponse.Model
      description: Model that generated the response
    - contextPath: OpenAI.ChatGPTResponse.Number of Completion Tokens
      description: Number of tokens in the completion (response)
    - contextPath: OpenAI.ChatGPTResponse.Number of Prompt Tokens
      description: Number of tokens in the prompt (input)
    - contextPath: OpenAI.ChatGPTResponse.Number of Total Tokens
      description: Total number of tokens in the completion and prompt
    - contextPath: OpenAI.ChatGPTResponse.id
      description: ChatGPT response ID
  - arguments:
    - description: Instruction
      name: prompt
      required: true
    - auto: PREDEFINED
      defaultValue: text-davinci-003
      description: The model which will generate the completion. Some models are suitable for natural language tasks, others specialize in code. For Azure OpenAI, this should be the name of the DEPLOYMENT, not the generic model name.
      name: model
      predefined:
      - text-davinci-003
      - text-curie-001
      - text-babbage-001
      - text-ada-001
      - code-davinci-002
      - code-cushman-001
    - defaultValue: "0.2"
      description: 'Controls randomness: Lowering results in less random completions.'
      name: temperature
    - defaultValue: "256"
      description: The maximum number of tokens to generate.
      name: max_tokens
    - defaultValue: "1"
      description: 'Controls Diversity via nucleus sampling: 0.5 means half of all likihood-weighted options are considered.'
      name: top_p
    - defaultValue: "0"
      description: How much to penalize new tokens based on their existing frequency in the text so far. Decreases the model's likelihood to repeat the same line verbatim.
      name: frequency_penalty
    - defaultValue: "0"
      description: How much to penalize new tokens based on whether they appear in the text so far. Increases the model's likelihood to talk about new topics.
      name: presence_penalty
    - defaultValue: "1"
      description: Generates best_of completions server-side and returns the "best" (the one with the lowest log probability per token). Results can't be streamed. When used with n, best_of controls the number of candidate completions and n specifies how many to return â€“ best_of must be greater than n. Note- Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop. This parameter cannot be used with gpt-35-turbo.
      name: best_of
    - description: Up to four sequences where the API will stop generating further tokens. The returned text won't contain the stop sequence.
      name: stop
    description: Enter an instruction and watch the API respond with a completion that attempts to match the context or pattern you provided.
    name: openai-completions
    outputs:
    - contextPath: OpenAI.Completions.id
      description: Id of the returned completion.
      type: string
    - contextPath: OpenAI.Completions.model
      description: The model which will generate the completion.
      type: string
    - contextPath: OpenAI.Completions.text
      description: Completed text generated by OpenAI?
      type: string
  - arguments:
    - description: Question to ask the model
      name: question
      required: true
    - description: Data for the model to use to answer the question. Either arg "text" or "entry_id" is required.
      name: text
    - description: Entry ID of file for the model to use to answer the question. Either arg "text" or "entry_id" is required.
      name: entry_id
    - defaultValue: text-davinci-003
      description: Name of model to use. Used for Azure OpenAI only.
      name: model
    - defaultValue: text-davinci-003
      description: Name of deployment to use. Used for Azure OpenAI only.
      name: deployment
    - defaultValue: "0.2"
      description: 'Controls randomness: Lowering results in less random completions.'
      name: temperature
    - description: Chat history to pass into the model to inform the answer to the current question. Must be in the format of the ${OpenAI.QA} context key from a previous output of the `openai-answer-question` command.
      isArray: true
      name: chat_history
    description: Ask the model a question to answer based on input data
    name: openai-answer-question
    outputs:
    - contextPath: OpenAI.QA.Question
      description: Question asked to the model
    - contextPath: OpenAI.QA.Answer
      description: Answer provided by the model
  - arguments:
    - description: Text for the model to summarize. Either arg "text" or "entry_id" is required.
      name: text
    - description: Entry ID of file for the model to summarize. Either arg "text" or "entry_id" is required.
      name: entry_id
    - description: Additional prompt to optionally add more specific instructions
      name: prompt
    - defaultValue: text-davinci-003
      description: Name of model to use. Used for Azure OpenAI only.
      name: model
    - defaultValue: text-davinci-003
      description: Name of deployment to use. Used for Azure OpenAI only.
      name: deployment
    - defaultValue: "0"
      description: 'Controls randomness: Lowering results in less random completions.'
      name: temperature
    description: Summarize the data provided to the model
    name: openai-summarize
    outputs:
    - contextPath: OpenAI.Summary
      description: Summary returned by the model
  dockerimage: demisto/python3:3.10.12.63474
  runonce: false
  script: ''
  subtype: python3
  type: python
fromversion: 6.9.0
tests:
- No tests (auto formatted)
